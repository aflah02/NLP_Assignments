{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "xURHYz8XsLoR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "id": "k-ptEnijslOo",
    "outputId": "7077eda8-1c04-4a89-f17e-ea5b286477a5"
   },
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('A1_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "RBquCbrZsny5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Fri Jun 05 14:26:50 2009</td>\n",
       "      <td>About to get threaded and scared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Thu May 14 10:13:55 2009</td>\n",
       "      <td>@awaisnaseer I like Shezan Mangooo too!!! I ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Fri Jun 05 21:02:20 2009</td>\n",
       "      <td>worked on my car after work. showering then go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Sun Jun 14 22:25:52 2009</td>\n",
       "      <td>@Marama Actually we start this afternoon!  I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Sun May 31 00:42:12 2009</td>\n",
       "      <td>@gfalcone601 Aww Gi.don't worry.we'll vote for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>1</td>\n",
       "      <td>Sat Jun 06 22:45:26 2009</td>\n",
       "      <td>@QandQ My performances on my CLEP tests.  #qshock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>0</td>\n",
       "      <td>Tue Jun 16 10:17:07 2009</td>\n",
       "      <td>ugh no, rcn had all the true blood episodes on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4284</th>\n",
       "      <td>1</td>\n",
       "      <td>Fri May 01 22:00:42 2009</td>\n",
       "      <td>Just returned from the forest! Sarah (my merch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4285</th>\n",
       "      <td>1</td>\n",
       "      <td>Sun Jun 07 02:09:46 2009</td>\n",
       "      <td>is proud of her dad and his piece of work. ( h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4286</th>\n",
       "      <td>0</td>\n",
       "      <td>Fri May 22 04:49:37 2009</td>\n",
       "      <td>Just woke up, gonna eat pizza for breakfast. A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4287 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LABEL                 DATE_TIME  \\\n",
       "0         0  Fri Jun 05 14:26:50 2009   \n",
       "1         1  Thu May 14 10:13:55 2009   \n",
       "2         1  Fri Jun 05 21:02:20 2009   \n",
       "3         1  Sun Jun 14 22:25:52 2009   \n",
       "4         1  Sun May 31 00:42:12 2009   \n",
       "...     ...                       ...   \n",
       "4282      1  Sat Jun 06 22:45:26 2009   \n",
       "4283      0  Tue Jun 16 10:17:07 2009   \n",
       "4284      1  Fri May 01 22:00:42 2009   \n",
       "4285      1  Sun Jun 07 02:09:46 2009   \n",
       "4286      0  Fri May 22 04:49:37 2009   \n",
       "\n",
       "                                                   TEXT  \n",
       "0                     About to get threaded and scared   \n",
       "1     @awaisnaseer I like Shezan Mangooo too!!! I ha...  \n",
       "2     worked on my car after work. showering then go...  \n",
       "3     @Marama Actually we start this afternoon!  I w...  \n",
       "4     @gfalcone601 Aww Gi.don't worry.we'll vote for...  \n",
       "...                                                 ...  \n",
       "4282  @QandQ My performances on my CLEP tests.  #qshock  \n",
       "4283  ugh no, rcn had all the true blood episodes on...  \n",
       "4284  Just returned from the forest! Sarah (my merch...  \n",
       "4285  is proud of her dad and his piece of work. ( h...  \n",
       "4286  Just woke up, gonna eat pizza for breakfast. A...  \n",
       "\n",
       "[4287 rows x 3 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "woQssMfKAQe3"
   },
   "outputs": [],
   "source": [
    "from customregexes import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAVPGC_8rRM7"
   },
   "source": [
    "# I. REGULAR EXPRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0n87jQodrSJ5"
   },
   "source": [
    "# A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtiD3IRnsvR0"
   },
   "source": [
    "## a. Average number of sentences and tokens \n",
    "- ! or ? (Even Continous)\n",
    "- . Followed by one or more spaces and then a capital character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "1-38IM7hfmVc"
   },
   "outputs": [],
   "source": [
    "df_data['sentence_count'] = df_data['TEXT'].apply(lambda x: findSentenceCount(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LABEL\n",
       "0    1.800500\n",
       "1    1.854832\n",
       "Name: sentence_count, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.groupby(['LABEL'])['sentence_count'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "GiDosJOaRAgw"
   },
   "outputs": [],
   "source": [
    "df_data['token_count'] = df_data['TEXT'].apply(lambda x: findTokenCount(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['tokens'] = df_data['TEXT'].apply(lambda x: findTokens(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zXZd-DZcsu_4",
    "outputId": "0d516035-5bdb-4aab-fc08-f6d6d3ba0f8a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LABEL\n",
       "0    14.811500\n",
       "1    14.139921\n",
       "Name: token_count, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.groupby(['LABEL'])['token_count'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Total number of words starting with consonants and vowels\n",
    "- Words starting with either Consonant or Vowel (depending on subpart) followed by either an alphabet, an accented alphabet, an apostrophe or a hyphen.\n",
    "- This was done to ensure no cases of say spanish text which creep in twitter data from countries like the U.S. are not missed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "21bourgDKKyL"
   },
   "outputs": [],
   "source": [
    "df_data['words_starting_with_vowel'] = df_data['TEXT'].apply(lambda x: countWordsStartingWithVowel(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nIUx_RhlqJkQ",
    "outputId": "1220f13f-7b0f-4796-eda8-53e5c875cfd7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14177"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['words_starting_with_vowel'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LABEL\n",
       "0    6989\n",
       "1    7188\n",
       "Name: words_starting_with_vowel, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.groupby(['LABEL'])['words_starting_with_vowel'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "wibwwaouCJDC"
   },
   "outputs": [],
   "source": [
    "df_data['words_starting_with_consonant'] = df_data['TEXT'].apply(lambda x: countWordsStartingWithConsonant(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ookPUBYcqHY8",
    "outputId": "f60386ca-600a-4767-8c56-79dc666d52b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37196"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['words_starting_with_consonant'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LABEL\n",
       "0    17995\n",
       "1    19201\n",
       "Name: words_starting_with_consonant, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.groupby(['LABEL'])['words_starting_with_consonant'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYRKw0v3Pq2n"
   },
   "source": [
    "## c. Lowercase the text and report the number of unique tokens present before and after lower casing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unique Tokens Before Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Fa4UbCdpPOoL"
   },
   "outputs": [],
   "source": [
    "def get_unique_tokens(tokens):\n",
    "    unique_tokens = set()\n",
    "    for token_list in tokens:\n",
    "        for token in token_list:\n",
    "            unique_tokens.add(token)\n",
    "    return len(unique_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = df_data['tokens'].to_list()\n",
    "df_data['lowercase_text'] = df_data['TEXT'].apply(lambda x: lowercase(x))\n",
    "df_data['lowercase_tokens'] = df_data['lowercase_text'].apply(lambda x: findTokens(x))\n",
    "lowercase_tokens = df_data['lowercase_tokens'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Tokens 13167\n",
      "Unique Lowercase Tokens 11565\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique Tokens\", get_unique_tokens(tokens))\n",
    "print(\"Unique Lowercase Tokens\", get_unique_tokens(lowercase_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_LABEL_0 = df_data[df_data['LABEL'] == 0]['tokens'].to_list()\n",
    "lowercase_tokens_LABEL_0 = df_data[df_data['LABEL'] == 0]['lowercase_tokens'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Tokens 6991\n",
      "Unique Lowercase Tokens 6215\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique Tokens\", get_unique_tokens(tokens_LABEL_0))\n",
    "print(\"Unique Lowercase Tokens\", get_unique_tokens(lowercase_tokens_LABEL_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_LABEL_1 = df_data[df_data['LABEL'] == 1]['tokens'].to_list()\n",
    "lowercase_tokens_LABEL_1 = df_data[df_data['LABEL'] == 1]['lowercase_tokens'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Tokens 8622\n",
      "Unique Lowercase Tokens 7615\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique Tokens\", get_unique_tokens(tokens_LABEL_1))\n",
    "print(\"Unique Lowercase Tokens\", get_unique_tokens(lowercase_tokens_LABEL_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdc4Ufy2XiVE"
   },
   "source": [
    "## d. Count and list all the usernames.\n",
    "\n",
    "Basic Rules and Assumptions:\n",
    "\n",
    "- According to [Twitter Guidelines](https://help.twitter.com/en/managing-your-account/twitter-username-rules)\n",
    "  - Your username cannot be longer than 15 characters. Your name can be longer (50 characters) or shorter than 4 characters, but usernames are kept shorter for the sake of ease.\n",
    "  - A username can only contain alphanumeric characters (letters A-Z, numbers 0-9) with the exception of underscores, as noted above. Check to make sure your desired username doesn't contain any symbols, dashes, or spaces.\n",
    "  - *Optional Rule to Spot Users* - Usernames containing the words Twitter or Admin cannot be claimed. No account names can contain Twitter or Admin unless they are official Twitter accounts.\n",
    "\n",
    "- Some experimentation with our Twitter Handle helped us reach the following conclusions:\n",
    "  - @UserName can't be placed with other alphanumeric characters so abc@user 9@user are not valid and won't tag the user\n",
    "  - X@UserName where X is a punctuation is valid but the following cases also don't allow tagging - \n",
    "    - @@xyz\n",
    "    - _@xyz\n",
    "\n",
    "Hence we propose regexes which actually find real tag matches instead of say a user just writing an @ somewhere in the tweet and it getting falsely matched as a tagged user when it really isn't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "QxPV1weuX1rn"
   },
   "outputs": [],
   "source": [
    "df_data['UserNames'] = df_data['TEXT'].apply(lambda x: findUsernames(x))\n",
    "df_data['UserNamesCounts'] = df_data['TEXT'].apply(lambda x: findUsernameCount(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tIRVTSpZqmDL",
    "outputId": "9d11b68b-019f-4731-c556-66324d14d6c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2108"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['UserNamesCounts'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username Count Label 0 -  803\n"
     ]
    }
   ],
   "source": [
    "print(\"Username Count Label 0 - \" , df_data[df_data['LABEL'] == 0]['UserNamesCounts'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username Count Label 1 -  1305\n"
     ]
    }
   ],
   "source": [
    "print(\"Username Count Label 1 - \" , df_data[df_data['LABEL'] == 1]['UserNamesCounts'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "1IQi6p5SqsHy"
   },
   "outputs": [],
   "source": [
    "usernames = df_data['UserNames'].to_numpy()\n",
    "flattened_usernames = []\n",
    "for i in usernames:\n",
    "  flattened_usernames.extend(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "We06hPGvrYVB",
    "outputId": "3ec7df54-41ab-4cde-8bf6-2aa8f5bc7cea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2021"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(flattened_usernames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9D-7fwqgYNe"
   },
   "source": [
    "## e. Count and list all the urls\n",
    "\n",
    "Basic Rules and Assumptions\n",
    "\n",
    "- `http`, `https`, `www` common starters for URLs usually\n",
    "- Manually investigating all sentences which contain `http` shows no false positives that is all occurences of `http` correspond to links\n",
    "- Manually investigating all sentences which contain `www` shows lots of false positives due to words like `aww`\n",
    "- On manual inspection we find no sentences which contain `https`\n",
    "- According to [Twitter's official Blog](https://help.twitter.com/en/using-twitter/url-shortener), Twitter uses a URL-Shortener which converts links to the form `t.co` however there are no positive matches for this in our dataset. The only matches that arise are spurious matches in links like `blogspot.com`\n",
    "- A URL maybe as simple as `www.xyz.abc` and as complex as `http://www.xyz.abc/efg` and can get even more complex by adding / to index more indepth into pages\n",
    "- There are false positives that we encounter such as `Gi.don` or `worry.we` but they are both valid URLs as well as there can be custom domains by those names. We assume the domain will be atleast 2 characters long to account for `.me`, `.uk` etc.\n",
    "- Numbers have been allowed as [only numbers can form valid URLs](https://stackoverflow.com/q/56804936/13858953)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "Pzjw7gUbgj3H"
   },
   "outputs": [],
   "source": [
    "df_data['URLs'] = df_data['TEXT'].apply(lambda x: findURLs(x))\n",
    "df_data['URLCounts'] = df_data['TEXT'].apply(lambda x: findURLCount(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL Count Label 0 -  60\n"
     ]
    }
   ],
   "source": [
    "print(\"URL Count Label 0 - \" , df_data[df_data['LABEL'] == 0]['URLCounts'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL Count Label 1 -  145\n"
     ]
    }
   ],
   "source": [
    "print(\"URL Count Label 1 - \" , df_data[df_data['LABEL'] == 1]['URLCounts'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jENr0Gqos6H"
   },
   "source": [
    "## f. Count the number of tweets for each day of the week. Eg Mon: 58, Tues: 20, Wed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "Dswe26lFmQi5"
   },
   "outputs": [],
   "source": [
    "df_data['Day'] = df_data['DATE_TIME'].apply(lambda x: getDay(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day Counts Label 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sun    565\n",
       "Fri    473\n",
       "Mon    391\n",
       "Thu    171\n",
       "Tue    154\n",
       "Wed    127\n",
       "Sat    119\n",
       "Name: Day, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Day Counts Label 0\")\n",
    "df_data[df_data['LABEL'] == 0]['Day'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VUuFLwxkqgqk",
    "outputId": "c85ced00-76f0-4e27-d429-61eafb57646d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day Counts Label 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sun    763\n",
       "Mon    481\n",
       "Fri    391\n",
       "Sat    298\n",
       "Wed    172\n",
       "Tue    132\n",
       "Thu     50\n",
       "Name: Day, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Day Counts Label 1\")\n",
    "df_data[df_data['LABEL'] == 1]['Day'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YQY-xmesj5X"
   },
   "source": [
    "# B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-itGBwas5XQ"
   },
   "source": [
    "## a. Total number of occurrences of the given word and sentences containing that word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "kCtBlSzwqiYl"
   },
   "outputs": [],
   "source": [
    "def re_find_word_in_sentence(word, sentence):\n",
    "  return len(re.findall(f'\\\\b{word}\\\\b', sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "PHLgD9f4tfmK"
   },
   "outputs": [],
   "source": [
    "def find_word_counts(df_data, word, class_label):\n",
    "  filtered_df = df_data[df_data['LABEL'] == class_label]\n",
    "  filtered_df['Counts'] = filtered_df['TEXT'].apply(lambda x: re_find_word_in_sentence(word, x))\n",
    "  total_occurence = sum(filtered_df['Counts'])\n",
    "  sentences_containing_word = filtered_df[filtered_df['Counts'] > 0]['TEXT'].to_list()\n",
    "  return total_occurence, sentences_containing_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WBTpIOtcticy",
    "outputId": "f4bdbdbf-9a5e-4927-8070-0ac1307c9b6b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_3216\\4136765138.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['Counts'] = filtered_df['TEXT'].apply(lambda x: re_find_word_in_sentence(word, x))\n"
     ]
    }
   ],
   "source": [
    "total_occurence, sentences_containing_word = find_word_counts(df_data, 'i', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EmWK4oTPts86",
    "outputId": "048479e4-abdb-4c91-ff15-f4d14d904e69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "REgyf0cnvEoa",
    "outputId": "5041960d-7124-4800-c039-ecc3c49218f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"@buckhollywood I Cant Watch That i'm in the UK  Can you tell me what its about? Please x\",\n",
       " '@mykiaisosm omj ur bad and mean i should not have meet u in 2nd grade even thouggh we hated each other i should have stayed like that ',\n",
       " ' i missed the game',\n",
       " \"dr office... hopefully finding out why i've been so sick  it's so hard to keep my eyes open\",\n",
       " 'i feel like death...my next investment?going to the spa! i need a new body that can function  (via @IngaDurgin)i herd sleep is good 4 dat']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_containing_word[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cx1eiKQNvZID"
   },
   "source": [
    "## b. Number of sentences starting with the given word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "C7f0n-rmvFeQ"
   },
   "outputs": [],
   "source": [
    "def re_find_sentence_starting_with_word(word, sentence):\n",
    "  if re.findall(f'^\\s*{word}\\\\b', sentence):\n",
    "    return 1\n",
    "  return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ohoOqq48wwA9",
    "outputId": "04378213-307e-40cd-b870-9c2adb72bae5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_find_sentence_starting_with_word(\"i\", \" am i \"), re_find_sentence_starting_with_word(\"i\", \" i am i \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "B4qf7D0tvjwr"
   },
   "outputs": [],
   "source": [
    "def find_all_sentences_starting_with_word(df_data, word, class_label):\n",
    "  filtered_df = df_data[df_data['LABEL'] == class_label]\n",
    "  filtered_df['Counts'] = filtered_df['TEXT'].apply(lambda x: re_find_sentence_starting_with_word(word, x))\n",
    "  total_occurence = sum(filtered_df['Counts'])\n",
    "  sentences_starting_with_word = filtered_df[filtered_df['Counts'] == 1]['TEXT'].to_list()\n",
    "  return total_occurence, sentences_starting_with_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ldBGVY_evmvH",
    "outputId": "dd9a0064-1eb6-4f95-f6d2-bfa91ac55e22"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_3216\\110637590.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['Counts'] = filtered_df['TEXT'].apply(lambda x: re_find_sentence_starting_with_word(word, x))\n"
     ]
    }
   ],
   "source": [
    "total_occurence, sentences_starting_with_word = find_all_sentences_starting_with_word(df_data, 'i', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3H49wwTwY48",
    "outputId": "ebda4a54-f32f-411c-a06b-1fff1085e02a",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52,\n",
       " [' i missed the game',\n",
       "  'i feel like death...my next investment?going to the spa! i need a new body that can function  (via @IngaDurgin)i herd sleep is good 4 dat',\n",
       "  \"i bet i was mistaking.. nah i'm not surprised \",\n",
       "  'i swear i just felt a earthquake  lol',\n",
       "  'i need to go out soon   i dont wanna but this weight aint gonna shift its self is it lol x',\n",
       "  \"i'm eating chocolate covered pretzels which is reminding me of Mallrats and making me not want to eat them anymore. \",\n",
       "  'i really miss photoshop ',\n",
       "  'i hate it im not yet done to my homework!! ',\n",
       "  \"i have officially lost all feeling in my legs! playing the sims 3 for seven hours isn't good... \",\n",
       "  \"i'm gonna miss those dayss \",\n",
       "  'i miss my feather duster ',\n",
       "  'i wish i was watching The Hills ',\n",
       "  'i miss @romylovesmcfly, anke and paula  i was going with them to tokio hotel.',\n",
       "  'i feel really bad i just talked to my parents like they were my slaves, and they were being so nice to me  punish me.',\n",
       "  \"i #blamedrewscancer for my b'day falling on a glorious sunny day this year &amp; me being cooped up in the office all day \",\n",
       "  'i hate being sick.&amp;in the same week as all my half yearlys, ahh poo ',\n",
       "  \"i can't make up my mind on what to wear \",\n",
       "  \"i has a headache.  i'm home alone doin stuff til 3-4 then partyin it upp!\",\n",
       "  \"i can't wait to play in leeds on my birthday, i wish i was on tour though! \",\n",
       "  'i dont want to pack! ',\n",
       "  'i have to leave ',\n",
       "  'i know i told him i didnt want him to stay home with me but i lied, i really did want him to stay home with me ',\n",
       "  \" i don't know, darlin. I'm so sorry. I wish i had what you need to make everything right.\",\n",
       "  'i think spoon is sick ',\n",
       "  \"i am watching the insider live and i sawed miley cyrus break up with nick......ummm isn't that old news? im just angry \",\n",
       "  \"i think i'm getting sick \",\n",
       "  'i dont want rudy to die oh my god i am going to cry why did death say that was going to happen ',\n",
       "  \"i miss my best friend!   we're one and the same &lt;3\",\n",
       "  'i wish our internet wasnt fucked. i could be doing any number of things right now ',\n",
       "  \"i hope THEY didn't return together \",\n",
       "  'i miss my crush ',\n",
       "  'i feel kind of sick.  hopefully supernatural will make me feel better.',\n",
       "  'i am cold ',\n",
       "  'i firmly believe the worst part of the working day is waiting for public transport - so boring. ',\n",
       "  \"i'm tired. and feel slightly ill. \",\n",
       "  'i dunno y @tweetpeete speaks of himself thru 3rd party tweets lol but @tweetpeete is mad cuz sports is finna suck til sunday ',\n",
       "  \"i'm so bored! i wanna go out with my friends.. \",\n",
       "  'i need to do my religion assignment, but its at school ',\n",
       "  \"i'm Bumbed about the lego batman being sold out \",\n",
       "  'i have to fill two hours ',\n",
       "  'i want my brother home so i can play sims 3 ',\n",
       "  'i didnt read cuz i felt to yucky so i had a yogut and that just made made me feel more yucky..damn teeth  and now i dont know what to eat',\n",
       "  'i dont want to start studying again today ',\n",
       "  'i blew up this balloon that tasted and smelt like burnt rubber and now i have a fricken headache    ',\n",
       "  'i am hungry but I ate so many bagels today i can feel them coming up. I needz a cheeseburger! ',\n",
       "  'i should be in malia right now! ',\n",
       "  \"i'm gunna cry when asher &amp; kay kiss in fame  better yet, i'll close my eyes.\",\n",
       "  'i fucking miss him so much ',\n",
       "  'i am about 99% sure that i just killed the new digital camera my parents got me yesterday ',\n",
       "  \"i'm sooo tired but i just can't seem to get to sleep! \",\n",
       "  'i am sad ',\n",
       "  'i wonder if there any anything as GIT tract transplant. i want to replace all my intestines to a healthier one '])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_occurence, sentences_starting_with_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxu11MKXwi_I"
   },
   "source": [
    "## c. Number of sentences ending with the given word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "58BVCGSnwguC"
   },
   "outputs": [],
   "source": [
    "def re_find_sentence_ending_with_word(word, sentence):\n",
    "  if re.findall(f'\\\\b{word}\\s*$', sentence):\n",
    "    return 1\n",
    "  return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NpfAFnRRw3J3",
    "outputId": "9ca64ae0-c694-4811-c6c4-8b208bef7831"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_find_sentence_ending_with_word(\"i\", \" am\"), re_find_sentence_ending_with_word(\"i\", \" i am i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "vB9e_reFw9ds"
   },
   "outputs": [],
   "source": [
    "def find_all_sentences_ending_with_word(df_data, word, class_label):\n",
    "  filtered_df = df_data[df_data['LABEL'] == class_label]\n",
    "  filtered_df['Counts'] = filtered_df['TEXT'].apply(lambda x: re_find_sentence_ending_with_word(word, x))\n",
    "  total_occurence = sum(filtered_df['Counts'])\n",
    "  sentences_ending_with_word = filtered_df[filtered_df['Counts'] == 1]['TEXT'].to_list()\n",
    "  return total_occurence, sentences_ending_with_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AQbh03oJxNgA",
    "outputId": "ca165aad-2375-4d41-98ba-f8ddb38b6e95"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_3216\\981797926.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['Counts'] = filtered_df['TEXT'].apply(lambda x: re_find_sentence_ending_with_word(word, x))\n"
     ]
    }
   ],
   "source": [
    "total_occurence, sentences_ending_with_word = find_all_sentences_ending_with_word(df_data, 'scared', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HIYOTYfTxQAn",
    "outputId": "dc4265ee-64aa-4e6b-9815-d17f9c83c31f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, ['About to get threaded and scared '])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_occurence, sentences_ending_with_word"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a5a87ee616be0254e3f1af9223138e3faeac65b2c9d91bc22a9fc5a4a8bd8eb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
