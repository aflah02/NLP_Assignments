{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffeval import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"preprocessed_A1.csv\"\n",
    "test_path = \"A2_test_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib2to3.pgen2.pgen import generate_grammar\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "from LanguageModels import *\n",
    "from preprocess_text import *\n",
    "\n",
    "def train_and_evaluate(train_sentences, train_labels, test_sentences, test_labels):\n",
    "    model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "    model.fit(train_sentences, train_labels)\n",
    "    predicted_test_labels = model.predict(test_sentences)\n",
    "    return accuracy_score(test_labels, predicted_test_labels)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = lowercase_text(text)\n",
    "    text = remove_url_html(text)\n",
    "    text = remove_users(text)\n",
    "    text = remove_punctuations(text)\n",
    "    text = remove_whitespaces(text)\n",
    "    text = tokenization(text)\n",
    "    text = spelling_correction(text)\n",
    "    text = remove_alphanum(text)\n",
    "    return ' '.join(text)\n",
    "\n",
    "class IntrinsicEvaluation:\n",
    "    \"\"\"\n",
    "    Perform Intrinsic Evaluation on the given generated sentences\n",
    "    \"\"\"\n",
    "    def __init__(self, generated_path):\n",
    "        self.generated_path = generated_path\n",
    "        \n",
    "    def get_perplexities(self):\n",
    "        with open(self.generated_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "        perplexities = []\n",
    "        sentences = []\n",
    "        for line in lines:\n",
    "            ppl = float(line.split(\" \")[-1].strip())\n",
    "            sentence = line.split(\" \")[:-1]\n",
    "            sentence = ' '.join(sentence)\n",
    "            perplexities.append(ppl)\n",
    "            sentences.append(sentence)\n",
    "        return perplexities, sentences\n",
    "\n",
    "    def get_avg_perplexity(self, perplexities):\n",
    "        return sum(perplexities)/len(perplexities)\n",
    "\n",
    "\n",
    "class ExtrinsicEvaluation:\n",
    "    \"\"\"\n",
    "    Perform Extrinsic Evaluation based on the Dataset type\n",
    "    \"\"\"\n",
    "    def __init__(self, train_path, test_path, addGen, generated_path_pos, generated_path_neg):\n",
    "        self.train_path = train_path\n",
    "        self.test_path = test_path\n",
    "        self.addGen = addGen\n",
    "        self.generated_path_pos = generated_path_pos\n",
    "        self.generated_path_neg = generated_path_neg\n",
    "    \n",
    "    def build_train(self):\n",
    "        train_df = pd.read_csv(self.train_path)\n",
    "        train_sentences = train_df['preprocessed_text']\n",
    "        for i in range(len(train_sentences)):\n",
    "            train_sentences[i] = eval(train_sentences[i])\n",
    "        train_labels = train_df['LABEL']\n",
    "\n",
    "        for i in range(len(train_sentences)):\n",
    "            train_sentences[i] = ' '.join(train_sentences[i])\n",
    "\n",
    "        train_sentences = train_sentences.values\n",
    "        train_labels = train_labels.values\n",
    "\n",
    "        if self.addGen == True:\n",
    "            with open(self.generated_path_pos, \"r\") as f:\n",
    "                lines1 = f.readlines()\n",
    "            with open(self.generated_path_neg, \"r\") as f:\n",
    "                lines2 = f.readlines()\n",
    "            lines = lines1 + lines2\n",
    "            generated_sentences = []\n",
    "            for line in lines:\n",
    "                sentence = line.split(\" \")[:-1]\n",
    "                sentence = ' '.join(sentence)\n",
    "                generated_sentences.append(sentence)\n",
    "            vader = SentimentIntensityAnalyzer()\n",
    "            generated_sentiments = []\n",
    "            generated_sentiments = [1]*250 + [0]*250\n",
    "            # for sentence in generated_sentences:\n",
    "            #     sentiment = vader.polarity_scores(sentence)\n",
    "            #     if sentiment['compound'] >= 0:\n",
    "            #         generated_sentiments.append(1)\n",
    "            #     elif sentiment['compound'] <= 0:\n",
    "            #         generated_sentiments.append(0)\n",
    "            # Concatenate the generated sentences with the original training sentences\n",
    "            train_sentences = np.concatenate((train_sentences, generated_sentences))\n",
    "            train_labels = np.concatenate((train_labels, generated_sentiments))\n",
    "        print(\"Train Sentences: \", len(train_sentences))\n",
    "        print(\"Train Labels: \", len(train_labels))\n",
    "        return train_sentences, train_labels\n",
    "    \n",
    "    def build_test(self):\n",
    "        test_df = pd.read_csv(\"A2_test_dataset_preprocessed.csv\")\n",
    "        # test_sentences = test_df['TEXT'].apply(preprocess_text)\n",
    "        test_sentences = test_df['pretext']\n",
    "        test_labels = test_df['LABEL']\n",
    "        test_labels = test_labels.values\n",
    "        return test_sentences.values, test_labels\n",
    "\n",
    "    def evaluate(self):\n",
    "        train_sentences, train_labels = self.build_train()\n",
    "        test_sentences, test_labels = self.build_test()\n",
    "        return train_and_evaluate(train_sentences, train_labels, test_sentences, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "extEval = ExtrinsicEvaluation(train_path, test_path, addGen=False, generated_path_pos=None, generated_path_neg=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_17376\\2916482393.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_sentences[i] = eval(train_sentences[i])\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_17376\\2916482393.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_sentences[i] = ' '.join(train_sentences[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Sentences:  4287\n",
      "Train Labels:  4287\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Desktop\\NLP_Assignments\\A2\\extrinsicEval.ipynb Cell 5\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Desktop/NLP_Assignments/A2/extrinsicEval.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m extEval\u001b[39m.\u001b[39;49mevaluate()\n",
      "\u001b[1;32md:\\Desktop\\NLP_Assignments\\A2\\extrinsicEval.ipynb Cell 5\u001b[0m in \u001b[0;36mExtrinsicEvaluation.evaluate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Desktop/NLP_Assignments/A2/extrinsicEval.ipynb#W3sZmlsZQ%3D%3D?line=110'>111</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Desktop/NLP_Assignments/A2/extrinsicEval.ipynb#W3sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m     train_sentences, train_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_train()\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Desktop/NLP_Assignments/A2/extrinsicEval.ipynb#W3sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m     test_sentences, test_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_test()\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Desktop/NLP_Assignments/A2/extrinsicEval.ipynb#W3sZmlsZQ%3D%3D?line=113'>114</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m train_and_evaluate(train_sentences, train_labels, test_sentences, test_labels)\n",
      "\u001b[1;32md:\\Desktop\\NLP_Assignments\\A2\\extrinsicEval.ipynb Cell 5\u001b[0m in \u001b[0;36mExtrinsicEvaluation.build_test\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Desktop/NLP_Assignments/A2/extrinsicEval.ipynb#W3sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_test\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Desktop/NLP_Assignments/A2/extrinsicEval.ipynb#W3sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m     test_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_path)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Desktop/NLP_Assignments/A2/extrinsicEval.ipynb#W3sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m     test_sentences \u001b[39m=\u001b[39m test_df[\u001b[39m'\u001b[39;49m\u001b[39mTEXT\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(preprocess_text)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Desktop/NLP_Assignments/A2/extrinsicEval.ipynb#W3sZmlsZQ%3D%3D?line=106'>107</a>\u001b[0m     test_labels \u001b[39m=\u001b[39m test_df[\u001b[39m'\u001b[39m\u001b[39mLABEL\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Desktop/NLP_Assignments/A2/extrinsicEval.ipynb#W3sZmlsZQ%3D%3D?line=107'>108</a>\u001b[0m     test_labels \u001b[39m=\u001b[39m test_labels\u001b[39m.\u001b[39mvalues\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\series.py:4357\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4247\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4248\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4249\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4252\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4253\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m FrameOrSeriesUnion:\n\u001b[0;32m   4254\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4255\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4256\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4355\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4356\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4357\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\apply.py:1043\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mstr\u001b[39m):\n\u001b[0;32m   1040\u001b[0m     \u001b[39m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m-> 1043\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\apply.py:1098\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1092\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m   1093\u001b[0m         \u001b[39m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m         \u001b[39m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1095\u001b[0m         \u001b[39m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1096\u001b[0m         \u001b[39m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m         \u001b[39m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1098\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1099\u001b[0m             values,\n\u001b[0;32m   1100\u001b[0m             f,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1101\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1102\u001b[0m         )\n\u001b[0;32m   1104\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1105\u001b[0m     \u001b[39m# GH 25959 use pd.array instead of tolist\u001b[39;00m\n\u001b[0;32m   1106\u001b[0m     \u001b[39m# so extension arrays can be used\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(pd_array(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\_libs\\lib.pyx:2859\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32md:\\Desktop\\NLP_Assignments\\A2\\extrinsicEval.ipynb Cell 5\u001b[0m in \u001b[0;36mpreprocess_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Desktop/NLP_Assignments/A2/extrinsicEval.ipynb#W3sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m text \u001b[39m=\u001b[39m remove_whitespaces(text)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Desktop/NLP_Assignments/A2/extrinsicEval.ipynb#W3sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m text \u001b[39m=\u001b[39m tokenization(text)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Desktop/NLP_Assignments/A2/extrinsicEval.ipynb#W3sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m text \u001b[39m=\u001b[39m spelling_correction(text)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Desktop/NLP_Assignments/A2/extrinsicEval.ipynb#W3sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m text \u001b[39m=\u001b[39m remove_alphanum(text)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Desktop/NLP_Assignments/A2/extrinsicEval.ipynb#W3sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(text)\n",
      "File \u001b[1;32md:\\Desktop\\NLP_Assignments\\A2\\preprocess_text.py:52\u001b[0m, in \u001b[0;36mspelling_correction\u001b[1;34m(text, method)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mspelling_correction\u001b[39m(text, method \u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mautocorrect_full\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     51\u001b[0m     \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mautocorrect_full\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m---> 52\u001b[0m         \u001b[39mreturn\u001b[39;00m spelling_correction_autocorrect_full_sentence(text)\n\u001b[0;32m     53\u001b[0m     \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mautocorrect_token\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     54\u001b[0m         \u001b[39mreturn\u001b[39;00m spelling_correction_autocorrect_per_token(text)\n",
      "File \u001b[1;32md:\\Desktop\\NLP_Assignments\\A2\\preprocess_text.py:30\u001b[0m, in \u001b[0;36mspelling_correction_autocorrect_full_sentence\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mspelling_correction_autocorrect_full_sentence\u001b[39m(text):\n\u001b[1;32m---> 30\u001b[0m     spell \u001b[39m=\u001b[39m Speller()\n\u001b[0;32m     31\u001b[0m     res \u001b[39m=\u001b[39m []\n\u001b[0;32m     32\u001b[0m     text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(text)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\autocorrect\\__init__.py:83\u001b[0m, in \u001b[0;36mSpeller.__init__\u001b[1;34m(self, lang, threshold, nlp_data, fast, only_replacements)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlang \u001b[39m=\u001b[39m lang\n\u001b[0;32m     82\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mthreshold \u001b[39m=\u001b[39m threshold\n\u001b[1;32m---> 83\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnlp_data \u001b[39m=\u001b[39m load_from_tar(lang) \u001b[39mif\u001b[39;00m nlp_data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m nlp_data\n\u001b[0;32m     84\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfast \u001b[39m=\u001b[39m fast\n\u001b[0;32m     85\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39monly_replacements \u001b[39m=\u001b[39m only_replacements\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\autocorrect\\__init__.py:73\u001b[0m, in \u001b[0;36mload_from_tar\u001b[1;34m(lang, file_name)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(\n\u001b[0;32m     67\u001b[0m             error_message\n\u001b[0;32m     68\u001b[0m             \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mFix your network connection, or manually download \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mand put it in \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mPATH_TO_REPO/autocorrect/data/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(url)\n\u001b[0;32m     70\u001b[0m         )\n\u001b[0;32m     72\u001b[0m \u001b[39mwith\u001b[39;00m closing(tarfile\u001b[39m.\u001b[39mopen(archive_name, \u001b[39m\"\u001b[39m\u001b[39mr:gz\u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39mas\u001b[39;00m tarf:\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mwith\u001b[39;00m closing(tarf\u001b[39m.\u001b[39;49mextractfile(file_name)) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m     74\u001b[0m         \u001b[39mreturn\u001b[39;00m json\u001b[39m.\u001b[39mload(file)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\tarfile.py:2113\u001b[0m, in \u001b[0;36mTarFile.extractfile\u001b[1;34m(self, member)\u001b[0m\n\u001b[0;32m   2110\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check(\u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2112\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(member, \u001b[39mstr\u001b[39m):\n\u001b[1;32m-> 2113\u001b[0m     tarinfo \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgetmember(member)\n\u001b[0;32m   2114\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2115\u001b[0m     tarinfo \u001b[39m=\u001b[39m member\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\tarfile.py:1797\u001b[0m, in \u001b[0;36mTarFile.getmember\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1791\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetmember\u001b[39m(\u001b[39mself\u001b[39m, name):\n\u001b[0;32m   1792\u001b[0m     \u001b[39m\"\"\"Return a TarInfo object for member `name'. If `name' can not be\u001b[39;00m\n\u001b[0;32m   1793\u001b[0m \u001b[39m       found in the archive, KeyError is raised. If a member occurs more\u001b[39;00m\n\u001b[0;32m   1794\u001b[0m \u001b[39m       than once in the archive, its last occurrence is assumed to be the\u001b[39;00m\n\u001b[0;32m   1795\u001b[0m \u001b[39m       most up-to-date version.\u001b[39;00m\n\u001b[0;32m   1796\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1797\u001b[0m     tarinfo \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getmember(name\u001b[39m.\u001b[39;49mrstrip(\u001b[39m'\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m   1798\u001b[0m     \u001b[39mif\u001b[39;00m tarinfo \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1799\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mfilename \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m not found\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m name)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\tarfile.py:2383\u001b[0m, in \u001b[0;36mTarFile._getmember\u001b[1;34m(self, name, tarinfo, normalize)\u001b[0m\n\u001b[0;32m   2379\u001b[0m \u001b[39m\"\"\"Find an archive member by name from bottom to top.\u001b[39;00m\n\u001b[0;32m   2380\u001b[0m \u001b[39m   If tarinfo is given, it is used as the starting point.\u001b[39;00m\n\u001b[0;32m   2381\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2382\u001b[0m \u001b[39m# Ensure that all members have been loaded.\u001b[39;00m\n\u001b[1;32m-> 2383\u001b[0m members \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgetmembers()\n\u001b[0;32m   2385\u001b[0m \u001b[39m# Limit the member search list up to tarinfo.\u001b[39;00m\n\u001b[0;32m   2386\u001b[0m \u001b[39mif\u001b[39;00m tarinfo \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\tarfile.py:1808\u001b[0m, in \u001b[0;36mTarFile.getmembers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1806\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check()\n\u001b[0;32m   1807\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_loaded:    \u001b[39m# if we want to obtain a list of\u001b[39;00m\n\u001b[1;32m-> 1808\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load()        \u001b[39m# all members, we first have to\u001b[39;00m\n\u001b[0;32m   1809\u001b[0m                         \u001b[39m# scan the whole archive.\u001b[39;00m\n\u001b[0;32m   1810\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmembers\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\tarfile.py:2406\u001b[0m, in \u001b[0;36mTarFile._load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2402\u001b[0m \u001b[39m\"\"\"Read through the entire archive file and look for readable\u001b[39;00m\n\u001b[0;32m   2403\u001b[0m \u001b[39m   members.\u001b[39;00m\n\u001b[0;32m   2404\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2405\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m-> 2406\u001b[0m     tarinfo \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext()\n\u001b[0;32m   2407\u001b[0m     \u001b[39mif\u001b[39;00m tarinfo \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2408\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\tarfile.py:2328\u001b[0m, in \u001b[0;36mTarFile.next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2326\u001b[0m \u001b[39m# Advance the file pointer.\u001b[39;00m\n\u001b[0;32m   2327\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moffset \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfileobj\u001b[39m.\u001b[39mtell():\n\u001b[1;32m-> 2328\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfileobj\u001b[39m.\u001b[39;49mseek(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moffset \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[0;32m   2329\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfileobj\u001b[39m.\u001b[39mread(\u001b[39m1\u001b[39m):\n\u001b[0;32m   2330\u001b[0m         \u001b[39mraise\u001b[39;00m ReadError(\u001b[39m\"\u001b[39m\u001b[39munexpected end of data\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\gzip.py:392\u001b[0m, in \u001b[0;36mGzipFile.seek\u001b[1;34m(self, offset, whence)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m READ:\n\u001b[0;32m    391\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_not_closed()\n\u001b[1;32m--> 392\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buffer\u001b[39m.\u001b[39;49mseek(offset, whence)\n\u001b[0;32m    394\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moffset\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\_compression.py:143\u001b[0m, in \u001b[0;36mDecompressReader.seek\u001b[1;34m(self, offset, whence)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[39m# Read and discard data until we reach the desired position.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[39mwhile\u001b[39;00m offset \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 143\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(\u001b[39mmin\u001b[39;49m(io\u001b[39m.\u001b[39;49mDEFAULT_BUFFER_SIZE, offset))\n\u001b[0;32m    144\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m data:\n\u001b[0;32m    145\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\gzip.py:495\u001b[0m, in \u001b[0;36m_GzipReader.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[39m# Read a chunk of data from the file\u001b[39;00m\n\u001b[0;32m    493\u001b[0m buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mread(io\u001b[39m.\u001b[39mDEFAULT_BUFFER_SIZE)\n\u001b[1;32m--> 495\u001b[0m uncompress \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decompressor\u001b[39m.\u001b[39;49mdecompress(buf, size)\n\u001b[0;32m    496\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decompressor\u001b[39m.\u001b[39munconsumed_tail \u001b[39m!=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    497\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mprepend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decompressor\u001b[39m.\u001b[39munconsumed_tail)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "extEval.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ExtrinsicEvaluation(train_path, test_path, addGen=True, generated_path_pos=r\"generated_sentences\\pos_gen_only_ext.txt\", generated_path_neg=r\"generated_sentences\\neg_gen_only_ext.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Desktop\\NLP_Assignments\\A2\\diffeval.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_sentences[i] = eval(train_sentences[i])\n",
      "d:\\Desktop\\NLP_Assignments\\A2\\diffeval.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_sentences[i] = ' '.join(train_sentences[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Sentences:  4787\n",
      "Train Labels:  4787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.906832298136646"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = ExtrinsicEvaluation(train_path, test_path, addGen=True, generated_path_pos=r\"generated_sentences\\pos_gen_add_numerator.txt\", generated_path_neg=r\"generated_sentences\\neg_gen_add_numerator.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Desktop\\NLP_Assignments\\A2\\diffeval.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_sentences[i] = eval(train_sentences[i])\n",
      "d:\\Desktop\\NLP_Assignments\\A2\\diffeval.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_sentences[i] = ' '.join(train_sentences[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Sentences:  4787\n",
      "Train Labels:  4787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8990683229813664"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ExtrinsicEvaluation(train_path, test_path, addGen=True, generated_path_pos=r\"generated_sentences\\pos_gen_div_denominator.txt\", generated_path_neg=r\"generated_sentences\\neg_gen_div_denominator.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Desktop\\NLP_Assignments\\A2\\diffeval.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_sentences[i] = eval(train_sentences[i])\n",
      "d:\\Desktop\\NLP_Assignments\\A2\\diffeval.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_sentences[i] = ' '.join(train_sentences[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Sentences:  4787\n",
      "Train Labels:  4787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9006211180124224"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ExtrinsicEvaluation(train_path, test_path, addGen=True, \n",
    "generated_path_pos=r\"generated_sentences\\pos_gen_mul_numerator.txt\", \n",
    "generated_path_neg=r\"generated_sentences\\neg_gen_mul_numerator.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Sentences:  4787\n",
      "Train Labels:  4787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8944099378881988"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = ExtrinsicEvaluation(train_path, test_path, addGen=True, \n",
    "generated_path_pos=r\"generated_sentences\\pos_hf_prompts.txt\", \n",
    "generated_path_neg=r\"generated_sentences\\neg_hf_prompts.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Desktop\\NLP_Assignments\\A2\\diffeval.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_sentences[i] = eval(train_sentences[i])\n",
      "d:\\Desktop\\NLP_Assignments\\A2\\diffeval.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_sentences[i] = ' '.join(train_sentences[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Sentences:  4787\n",
      "Train Labels:  4787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8881987577639752"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ExtrinsicEvaluation(train_path, test_path, addGen=True, \n",
    "generated_path_pos=r\"generated_sentences\\pos_ppl_normalized.txt\", \n",
    "generated_path_neg=r\"generated_sentences\\neg_ppl_normalized.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Desktop\\NLP_Assignments\\A2\\diffeval.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_sentences[i] = eval(train_sentences[i])\n",
      "d:\\Desktop\\NLP_Assignments\\A2\\diffeval.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_sentences[i] = ' '.join(train_sentences[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Sentences:  4787\n",
      "Train Labels:  4787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8819875776397516"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = ExtrinsicEvaluation(train_path, test_path, addGen=True, \n",
    "generated_path_pos=r\"generated_sentences\\pos_vader_textblob.txt\", \n",
    "generated_path_neg=r\"generated_sentences\\neg_vader_textblob.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Desktop\\NLP_Assignments\\A2\\diffeval.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_sentences[i] = eval(train_sentences[i])\n",
      "d:\\Desktop\\NLP_Assignments\\A2\\diffeval.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_sentences[i] = ' '.join(train_sentences[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Sentences:  4787\n",
      "Train Labels:  4787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.889751552795031"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5a87ee616be0254e3f1af9223138e3faeac65b2c9d91bc22a9fc5a4a8bd8eb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
